import streamlit as st
import os
import pickle
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image
from sklearn.manifold import TSNE
import torch
from transformers import AutoImageProcessor, AutoModel
import io
import base64

# --- Page Config ---
st.set_page_config(page_title="Sketchfab Style Explorer", layout="wide", page_icon="ğŸ¦–")

# --- Constants ---
EMBEDDINGS_FILE = "sketchfab_tools/sketchfab_embeddings.pkl"
IMAGE_DIR = "sketchfab_data"
MODEL_ID = "facebook/dinov2-base"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# --- Cached Functions ---
@st.cache_resource
def load_dino_model():
    processor = AutoImageProcessor.from_pretrained(MODEL_ID)
    model = AutoModel.from_pretrained(MODEL_ID).to(DEVICE)
    model.eval()
    return processor, model

@st.cache_data
def load_dataset_embeddings(mtime):
    """íŒŒì¼ ìˆ˜ì • ì‹œê°„ì„ ê°ì§€í•˜ì—¬ ìºì‹œë¥¼ ìë™ ê°±ì‹ í•©ë‹ˆë‹¤."""
    if not os.path.exists(EMBEDDINGS_FILE):
        return {}
    with open(EMBEDDINGS_FILE, 'rb') as f:
        return pickle.load(f)

def extract_vector(image, processor, model):
    img = image.convert("RGB")
    
    # [ì¶”ê°€] ì¬ì§ˆ(Style)ì— ë” ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ì¤‘ì•™ í¬ë¡­ (ë¶„ì„ê¸°ì™€ ë™ì¼í•˜ê²Œ 70% ì˜ì—­)
    w, h = img.size
    left, top, right, bottom = w * 0.15, h * 0.15, w * 0.85, h * 0.85
    img = img.crop((left, top, right, bottom))
    
    inputs = processor(images=img, return_tensors="pt").to(DEVICE)
    with torch.no_grad():
        outputs = model(**inputs)
        # [ìˆ˜ì •] CLS ëŒ€ì‹  íŒ¨ì¹˜ í† í°ì˜ í‰ê· (GAP) ì‚¬ìš©
        patch_tokens = outputs.last_hidden_state[:, 1:, :]
        return patch_tokens.mean(dim=1).cpu().numpy()

# --- App Structure ---
st.title("ğŸ¦– Sketchfab Style Explorer")
st.markdown("ë‚˜ë§Œì˜ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì—¬ Sketchfab ì¤‘ì„¸ ìì‚°ë“¤ê³¼ì˜ ìŠ¤íƒ€ì¼ ìœ ì‚¬ë„ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")

sidebar = st.sidebar
sidebar.header("ğŸ“ ë°ì´í„° ì„¤ì •")

# 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
processor, model = load_dino_model()
file_mtime = os.path.getmtime(EMBEDDINGS_FILE) if os.path.exists(EMBEDDINGS_FILE) else 0
embeddings_dict = load_dataset_embeddings(file_mtime)

if not embeddings_dict:
    st.error(f"ì„ë² ë”© ë°ì´í„°({EMBEDDINGS_FILE})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶„ì„ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# 2. ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„¹ì…˜ (ë©”ì¸ í˜ì´ì§€ ìƒë‹¨ì— ë°°ì¹˜)
st.info("ğŸ’¡ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ë˜ì–´ ê·¸ë˜í”„ì— **ë¹¨ê°„ ë³„(â˜…)**ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
uploaded_file = st.file_uploader("ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ì‚¬ì§„ ì—…ë¡œë“œ (ë””ìì¸ ì‹œì•ˆ, ì°¸ê³  ì‚¬ì§„ ë“±)", type=["jpg", "jpeg", "png"])

all_vectors = []
all_names = []
all_types = []
all_paths = []

# ë°ì´í„°ì…‹ ì„ë² ë”© ì¶”ê°€
for filename, vec_np in embeddings_dict.items():
    all_vectors.append(vec_np.squeeze())
    all_names.append(filename.split("_")[-1].replace(".jpg", ""))
    all_types.append("Sketchfab Dataset")
    all_paths.append(os.path.join(IMAGE_DIR, filename))

# ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì„ë² ë”© ì¶”ì¶œ ë° ì¶”ê°€
query_vec = None
if uploaded_file:
    with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
        query_image = Image.open(uploaded_file)
        query_vec = extract_vector(query_image, processor, model)
        
        all_vectors.append(query_vec.squeeze())
        all_names.append("YOUR_UPLOAD")
        all_types.append("YOUR IMAGE")
        # ì¿¼ë¦¬ ì´ë¯¸ì§€ëŠ” ê²½ë¡œ ëŒ€ì‹  PIL ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ None ì²˜ë¦¬í•˜ê±°ë‚˜ ì„ì‹œ ì €ì¥
        all_paths.append(uploaded_file)

# 3. t-SNE ê³„ì‚°
with st.spinner("ìœ ì‚¬ë„ ê³µê°„ ê³„ì‚° ì¤‘..."):
    vectors_array = np.array(all_vectors)
    perplexity = min(30, len(all_vectors) - 1)
    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, init='pca', learning_rate='auto')
    vectors_2d = tsne.fit_transform(vectors_array)

# 4. ì‹œê°í™” ë° ì¸í„°ë™ì…˜
if "highlighted_idx" not in st.session_state:
    st.session_state.highlighted_idx = None

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ í™•ë³´ (ì´ë¯¸ì§€ ë¡œë”©ìš©)
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
ABS_IMAGE_DIR = os.path.join(PROJECT_ROOT, "sketchfab_data")

df_plot = {
    "index": list(range(len(all_names))),
    "x": vectors_2d[:, 0],
    "y": vectors_2d[:, 1],
    "Name": all_names,
    "Type": all_types,
    "Path": []
}

# ê²½ë¡œ ì¬ì„¤ì • (í™•ì‹¤í•œ ì ˆëŒ€ê²½ë¡œ)
for i, p in enumerate(all_paths):
    if isinstance(p, str):
        # íŒŒì¼ëª…ë§Œ ì¶”ì¶œí•´ì„œ ABS_IMAGE_DIRê³¼ ê²°í•©
        fname = os.path.basename(p)
        df_plot["Path"].append(os.path.join(ABS_IMAGE_DIR, fname))
    else:
        df_plot["Path"].append(p)

st.subheader("ğŸ“ Style Similarity Map")
st.caption("Lasso Select(ì˜¬ê°€ë¯¸)ë‚˜ Box Selectë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì—­ì„ ì„ íƒí•˜ë©´ í•˜ë‹¨ì— ì¸ë„¤ì¼ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

fig = px.scatter(
    df_plot, x="x", y="y", color="Type",
    hover_name="Name",
    color_discrete_map={"Sketchfab Dataset": "#636EFA", "YOUR IMAGE": "#EF553B"},
    height=600,
    template="plotly_dark",
    labels={"x": "Style A", "y": "Style B"},
    custom_data=["index"]
)

fig.update_traces(marker=dict(size=14, opacity=0.8))
if query_vec is not None:
    fig.update_traces(
        selector=dict(name="YOUR IMAGE"),
        marker=dict(size=35, symbol="star", line=dict(width=3, color="white"))
    )

if st.session_state.highlighted_idx is not None:
    idx = st.session_state.highlighted_idx
    if idx < len(vectors_2d): # Ensure index is within bounds
        fig.add_trace(go.Scatter(
            x=[vectors_2d[idx, 0]], y=[vectors_2d[idx, 1]],
            mode='markers',
            marker=dict(
                size=30, 
                color='#FFFF00', # Bright Yellow
                symbol='star', 
                line=dict(width=2, color='white')
            ),
            name="Selected Location",
            showlegend=False,
            hoverinfo='skip'
        ))

# ë””ë²„ê·¸ìš© (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
# st.write(f"Debug: Project Root = {PROJECT_ROOT}")
event = st.plotly_chart(fig, use_container_width=True, on_select="rerun", key="style_map")

# 5. ì„ íƒëœ í•­ëª© ê°¤ëŸ¬ë¦¬ (ì•„ë˜ìª½)
st.divider()
st.subheader("ğŸ–¼ï¸ Selected Assets Gallery")

def img_to_base64(path_or_file):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜í•˜ì—¬ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ í‘œì‹œë˜ê²Œ í•©ë‹ˆë‹¤."""
    try:
        if isinstance(path_or_file, str):
            if not os.path.exists(path_or_file):
                return None
            with open(path_or_file, "rb") as f:
                data = f.read()
        else: # UploadedFile
            data = path_or_file.getvalue()
        return base64.b64encode(data).decode()
    except Exception as e:
        return None

# ì´ë²¤íŠ¸ ìº¡ì²˜ ë””ë²„ê·¸ ë° ì¸ë±ìŠ¤ ì¶”ì¶œ
selected_indices = []
if event and "selection" in event:
    pts = event["selection"].get("points", [])
    if pts:
        st.success(f"DEBUG: {len(pts)}ê°œì˜ í¬ì¸íŠ¸ê°€ ì„ íƒë¨")
        for p in pts:
            # 1. custom_data ìš°ì„  í™•ì¸
            if "custom_data" in p and p["custom_data"] is not None:
                selected_indices.append(p["custom_data"][0])
            # 2. point_indexë¥¼ ì°¨ì„ ì±…ìœ¼ë¡œ ì‚¬ìš© (ë‹¨ì¼ íŠ¸ë ˆì´ìŠ¤ì¼ ë•Œ ìœ ë¦¬)
            elif "point_index" in p:
                selected_indices.append(p["point_index"])

if not selected_indices:
    st.info("ê·¸ë˜í”„ì—ì„œ ì ì„ í´ë¦­í•˜ê±°ë‚˜ ë§ˆìš°ìŠ¤ë¡œ ì˜ì—­ì„ ë“œë˜ê·¸(Box/Lasso)í•˜ì—¬ ì„ íƒí•´ì£¼ì„¸ìš”.")
else:
    # ì¤‘ë³µ ì œê±° ë° ìœ íš¨ ë²”ìœ„ í™•ì¸
    unique_indices = list(dict.fromkeys(selected_indices))
    valid_indices = [idx for idx in unique_indices if idx < len(all_names)]
    
    # ê°¤ëŸ¬ë¦¬ ê·¸ë¦¬ë“œ êµ¬ì„±
    cols = st.columns(5)
    for i, idx in enumerate(valid_indices):
        with cols[i % 5]:
            path = df_plot["Path"][idx]
            name = df_plot["Name"][idx]
            
            # Base64 ë³€í™˜ ë° í‘œì‹œ
            b64_img = img_to_base64(path)
            
            if b64_img:
                # ìº¡ì…˜ê³¼ ì´ë¯¸ì§€ë¥¼ ë¬¶ì–´ì„œ í‘œì‹œ
                st.markdown(f"**{name[:15]}**")
                st.markdown(f'<img src="data:image/jpeg;base64,{b64_img}" style="width:100%; border-radius:10px; border: 2px solid #444;">', unsafe_allow_html=True)
            else:
                st.warning(f"Image Missing: {name}")
            
            # í•˜ì´ë¼ì´íŠ¸ ë²„íŠ¼
            if st.button(f"ğŸ” ìœ„ì¹˜ ì°¾ê¸°", key=f"gal_btn_{idx}_{i}"):
                st.session_state.highlighted_idx = idx
                st.rerun()
            
            # ì™¸ë¶€ ë§í¬
            if df_plot["Type"][idx] == "Sketchfab Dataset" and isinstance(path, str):
                model_id = os.path.basename(path).split("_")[0]
                st.caption(f"[Sketchfabì—ì„œ ë³´ê¸°](https://sketchfab.com/3d-models/{model_id})")

# í‘¸í„°
st.markdown("<br><br><br>", unsafe_allow_html=True)
st.divider()
st.caption("DINOv2 GAP Features + t-SNE | Interactive Style Explorer | PolyForge")
